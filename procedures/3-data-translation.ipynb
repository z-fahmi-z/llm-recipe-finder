{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "d9bc2d9d607d9494",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get dataframe\n",
    "import pandas as pd\n",
    "chickens = pd.read_csv(\"../csv/cleaned/chickens_cleaned.csv\")\n",
    "chickens"
   ],
   "id": "3eea5a7b2690dae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_input = f\"\"\"{{['{chickens.loc[0]['Title']}','{chickens.loc[0]['Ingredients']}','{chickens.loc[0]['Steps']}],['{chickens.loc[1]['Title']}','{chickens.loc[1]['Ingredients']}','{chickens.loc[1]['Steps']}],['{chickens.loc[2]['Title']}','{chickens.loc[2]['Ingredients']}','{chickens.loc[2]['Steps']}]'}}\"\"\"\n",
    "test_input"
   ],
   "id": "7ae706b50558fe29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "translated = GoogleTranslator(source='id', target='en').translate(test_input)\n",
    "print(translated)"
   ],
   "id": "4fdc7b10ed3f9869",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load deepseek v3 tokenizer\n",
    "import transformers\n",
    "chat_tokenizer_dir = \"../deepseek_v3_tokenizer\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(chat_tokenizer_dir, trust_remote_code=True)"
   ],
   "id": "3c772c2771b7e203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load system prompt as string\n",
    "system_prompt = open(\"../system-prompts/translator_v2.json\").read().replace('\\n', '').replace(' ', '')\n",
    "system_prompt"
   ],
   "id": "43d32b030087dfe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count system_prompt tokens\n",
    "calculated_system_prompt_token = len(tokenizer.encode(system_prompt))\n",
    "print(\"Tokens {system_prompt} =\", calculated_system_prompt_token)"
   ],
   "id": "f4c22eab965846cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count test_input query tokens\n",
    "query = \"Input: \" + test_input\n",
    "print(\"Tokens {query} =\", len(tokenizer.encode(query)))"
   ],
   "id": "3c29a121670dbe44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get relevant columns:values as list\n",
    "subset_chickens = chickens[[\"Title\", \"Ingredients\", \"Steps\"]]\n",
    "chickens_as_list = subset_chickens.values.tolist()\n",
    "chickens_as_list"
   ],
   "id": "7009ff53bb6c2b38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_batches(df_rows, rows_per_batch):\n",
    "    return int(df_rows / rows_per_batch + 1)\n",
    "\n",
    "ROWS_PER_BATCH = 21\n",
    "TOTAL_ROWS = len(subset_chickens)\n",
    "batches_number = calculate_batches(TOTAL_ROWS, ROWS_PER_BATCH)\n",
    "print(f\"Number of batches ({ROWS_PER_BATCH} rows each) = {batches_number}\")"
   ],
   "id": "5296c54d08735427",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert to chunks\n",
    "import numpy as np\n",
    "batches = np.array_split(chickens_as_list, batches_number)\n",
    "print(len(batches))"
   ],
   "id": "452acc0baf31eb45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bulk = batches[0].tolist()\n",
    "bulk_as_json = \"{\"+ str(bulk)[1:-1] +\"}\"\n",
    "print(len(bulk))"
   ],
   "id": "fbef7d7c65179c72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count batch input tokens\n",
    "query = \"Input: \" + bulk_as_json\n",
    "calculated_query_token = len(tokenizer.encode(query))\n",
    "print(\"Tokens {query} =\", calculated_query_token)"
   ],
   "id": "4801b65ddf2a97f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "deepseek_v3 = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=4096,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    ")\n",
    "\n",
    "async def async_list_converter(sync_list):\n",
    "    for item in sync_list:\n",
    "        yield item\n",
    "\n",
    "def validate_llm_output_format(output, collection_closure=\"]```\", element_closure=\"}\"):\n",
    "    closure_begin_index = len(output) - len(collection_closure)\n",
    "    if output[closure_begin_index:] != collection_closure:\n",
    "        refactored = output\n",
    "        last_unfinished_index = refactored.rfind(element_closure) + 1\n",
    "        refactored = refactored[:last_unfinished_index] + collection_closure\n",
    "        return refactored\n",
    "    return output\n",
    "\n",
    "async def process_batch(batch):\n",
    "    batch_as_list = batch.tolist()\n",
    "    batch_as_payload = \"Input: {\"+ str(batch_as_list)[1:-1] +\"}\"\n",
    "    messages = [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", batch_as_payload),\n",
    "    ]\n",
    "    response = await deepseek_v3.ainvoke(messages)\n",
    "    response.content = validate_llm_output_format(response.content)\n",
    "    return response\n",
    "\n",
    "async def process_batches(batches_to_process):\n",
    "    tasks = [process_batch(batch) async for batch in async_list_converter(batches_to_process)]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "results = await process_batches(batches)\n",
    "print(results, len(results))"
   ],
   "id": "fae72b449e149ce3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "def parse_llm_outputs_to_json_array(outputs):\n",
    "    json_array = []\n",
    "    for output in outputs:\n",
    "        content = output.content.strip('```json\\n').strip('```')\n",
    "        parsed = json.loads(content)\n",
    "        json_array += parsed\n",
    "    return json_array\n",
    "\n",
    "recipes = parse_llm_outputs_to_json_array(results)\n",
    "recipes"
   ],
   "id": "969868b67d767ca1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create new dataframe with the output\n",
    "translated_recipes = pd.DataFrame(recipes)\n",
    "translated_recipes"
   ],
   "id": "fac220f84859461d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "translated_recipes.to_csv(\"../csv/translated/chickens_translated_en.csv\", index=False)",
   "id": "113352824b7d5fca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inspect response token usage\n",
    "# usage = response.usage\n",
    "# expected_tokens_usage = calculated_query_token + calculated_system_prompt_token\n",
    "# divider = \"â”€\" * 35\n",
    "# print(f\"\"\"\n",
    "# Token Details:\n",
    "# {divider}\n",
    "# Prompt Cache Hit: {usage.prompt_cache_hit_tokens}\n",
    "# Prompt Cache Miss: {usage.prompt_cache_miss_tokens}\n",
    "#\n",
    "# Token Usage:\n",
    "# {divider}\n",
    "# Expected Prompt tokens: {expected_tokens_usage}\n",
    "# Actual Prompt tokens: {usage.prompt_tokens}\n",
    "# Difference : {usage.prompt_tokens - expected_tokens_usage}\n",
    "# Completion tokens: {usage.completion_tokens}\n",
    "# Total tokens: {usage.total_tokens}\n",
    "# \"\"\")\n",
    "# Available parameters:\n",
    "# created=, model='deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='', usage=CompletionUsage(completion_tokens=, prompt_tokens=, total_tokens=, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=), prompt_cache_hit_tokens=, prompt_cache_miss_tokens=))"
   ],
   "id": "6be4dc0b0ca87a88",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
