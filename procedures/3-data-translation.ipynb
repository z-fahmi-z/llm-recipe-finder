{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "d9bc2d9d607d9494",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get dataframe\n",
    "import pandas as pd\n",
    "chickens = pd.read_csv(\"../csv/cleaned/lambs_cleaned.csv\")\n",
    "chickens"
   ],
   "id": "3eea5a7b2690dae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test out suitable input format\n",
    "test_input = f\"\"\"{{['{chickens.loc[0]['Title']}','{chickens.loc[0]['Ingredients']}','{chickens.loc[0]['Steps']}],['{chickens.loc[1]['Title']}','{chickens.loc[1]['Ingredients']}','{chickens.loc[1]['Steps']}],['{chickens.loc[2]['Title']}','{chickens.loc[2]['Ingredients']}','{chickens.loc[2]['Steps']}]'}}\"\"\"\n",
    "test_input"
   ],
   "id": "7ae706b50558fe29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Review GoogleTranslator API results\n",
    "from deep_translator import GoogleTranslator\n",
    "translated_with_google_api = GoogleTranslator(source='id', target='en').translate(test_input)\n",
    "translated_with_google_api"
   ],
   "id": "4fdc7b10ed3f9869",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load deepseek v3 tokenizer\n",
    "import transformers\n",
    "chat_tokenizer_dir = \"../deepseek_v3_tokenizer\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(chat_tokenizer_dir, trust_remote_code=True)"
   ],
   "id": "3c772c2771b7e203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load system prompt\n",
    "system_prompt = open(\"../system-prompts/translator_v2.json\").read().replace('\\n', '').replace(' ', '')\n",
    "system_prompt"
   ],
   "id": "43d32b030087dfe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estimate system_prompt tokens\n",
    "calculated_system_prompt_token = len(tokenizer.encode(system_prompt))\n",
    "print(\"Estimated Tokens {system_prompt} = \", calculated_system_prompt_token)"
   ],
   "id": "f4c22eab965846cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estimate test_input query tokens with 3 bulk\n",
    "query = \"Input: \" + test_input\n",
    "print(\"Estimated Tokens {query} = \", len(tokenizer.encode(query)))"
   ],
   "id": "3c29a121670dbe44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get relevant columns:values as list\n",
    "subset_chickens = chickens[[\"Title\", \"Ingredients\", \"Steps\"]]\n",
    "chickens_as_list = subset_chickens.values.tolist()\n",
    "chickens_as_list"
   ],
   "id": "7009ff53bb6c2b38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Batching dataframe\n",
    "def calculate_batches(df_rows, rows_per_batch):\n",
    "    return int(df_rows / rows_per_batch + 1)\n",
    "\n",
    "ROWS_PER_BATCH = 21\n",
    "TOTAL_ROWS = len(subset_chickens)\n",
    "\n",
    "batches_number = calculate_batches(TOTAL_ROWS, ROWS_PER_BATCH)\n",
    "print(f\"Expected number of batches ({ROWS_PER_BATCH} rows each) = {batches_number}\")"
   ],
   "id": "5296c54d08735427",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert df to batches\n",
    "import numpy as np\n",
    "batches = np.array_split(chickens_as_list, batches_number)\n",
    "print(f\"Number of batches created = {len(batches)}\")"
   ],
   "id": "cdc949a3bdabcce9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "element_delimiters = ['{', '}']\n",
    "print(f\"Input: {element_delimiters[0]}{str(batches[0].tolist())[1:-1]}{element_delimiters[1]}\")"
   ],
   "id": "452acc0baf31eb45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estimate batch input tokens\n",
    "bulk = str(batches[0].tolist())[1:-1]\n",
    "bulk_query = f\"Input: {element_delimiters[0]}{bulk}{element_delimiters[1]}\"\n",
    "bulk_query"
   ],
   "id": "31308d4190419988",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "calculated_query_token = len(tokenizer.encode(query))\n",
    "print(\"Estimated Tokens {bulk_query} = \", calculated_query_token)"
   ],
   "id": "52799dc281b1374d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "deepseek_v3 = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=4096,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    ")"
   ],
   "id": "7aeee5e3ccda83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load LlmTranslator helper\n",
    "from helpers.async_translate import LlmTranslator\n",
    "\n",
    "# Define default delimiters according to system_prompt return format\n",
    "collection_delimiters = ['```json\\n[', ']```']\n",
    "element_delimiters = ['{', '}']\n",
    "\n",
    "# Configure LlmTranslator class\n",
    "llm_translator = LlmTranslator(\n",
    "    deepseek_v3,\n",
    "    system_prompt,\n",
    "    collection_delimiters=collection_delimiters,\n",
    "    element_delimiters=element_delimiters\n",
    ")\n",
    "\n",
    "# Jupyter handles event loop, asyncio.run() is unnecessary\n",
    "results = await llm_translator.process_batches(batches)\n",
    "print(results, len(results))"
   ],
   "id": "c2a3b37c96f945d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helpers.output_processor import parse_llm_outputs_to_json_array\n",
    "strip_delimiters = ['```json\\n', '```']\n",
    "recipes = parse_llm_outputs_to_json_array(results, strip_delimiters)\n",
    "recipes"
   ],
   "id": "79cd836605cdf445",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create new dataframe with the output\n",
    "translated_recipes = pd.DataFrame(recipes)\n",
    "translated_recipes"
   ],
   "id": "a1d43540655850fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "translated_recipes.to_csv(\"../csv/translated/lambs_translated_en.csv\", index=False)",
   "id": "b07846880b96fc59",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
